defaults:
  - _self_
  - wandb: private.yaml
  - augmentations: linear.yaml
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# disable hydra outputs
hydra:
  output_subdir: null
  run:
    dir: .

name: "mocov2plus-linear--horizontal-isic2019"
finetune: False # perform finetune or linear-probbing
knn_eval:
  enabled: True
  k: 20
  distance_func: "cosine"
pretrain:
  method: "mocov2plus"
  #ckpt: "trained_models/mocov2plus/bp5i1erd/mocov2plus-bp5i1erd-ep=99.ckpt" # pretrain ckpt
  # ckpt: "trained_models/mocov2plus/rwmvyznl/mocov2plus-symmetric-rwmvyznl-ep=99.ckpt" # symmetric
  # ckpt: "trained_models/mocov2plus/wrl90zkm/mocov2plus--color_jitter-wrl90zkm-ep=99.ckpt" # -color jitter
  # ckpt: "trained_models/mocov2plus/kn91yno6/mocov2plus--graycale-kn91yno6-ep=99.ckpt" # -grayscale
  # ckpt: "trained_models/mocov2plus/ic10r2ww/mocov2plus--guassian_blur.yaml-ic10r2ww-ep=99.ckpt" # -guassian
  # ckpt: "trained_models/mocov2plus/egfrdeb9/mocov2plus--vetical-egfrdeb9-ep=99.ckpt" # -vertical
  ckpt: "trained_models/mocov2plus/mx6gddde/mocov2plus--horizontal-mx6gddde-ep=99.ckpt" # -horizontal 
  # ckpt: "trained_models/mocov2plus/zo7viqnq/mocov2plus--solarization.yaml-zo7viqnq-ep=99.ckpt" # solarization
  # ckpt: "trained_models/mocov2plus/s1g7cdmh/mocov2plus--rotate-s1g7cdmh-ep=99.ckpt" # -rotate
  ckpt_key: "momentum_backbone" #ckpt key in ["backbone", "momentum_backbone"]
backbone:
  name: "resnet18"
loss_fn: 
  name: "ce" # choose from [ce, focal, label_smoothing_ce, soft_target_ce]
data:
  dataset: isic2019
  data_path: "data/pretrain/images"
  train_label: "data/pretrain/ISIC_2019_train.csv"
  val_label: "data/pretrain/ISIC_2019_test.csv"
  num_workers: 10
  debug_transform: True
optimizer:
  name: "sgd"
  batch_size: 512
  lr: 0.01
  weight_decay: 0
scheduler:
  name: step
  lr_decay_steps: [60, 80]
checkpoint:
  enabled: True
  dir: "trained_models"
  frequency: 1
auto_resume:
  enabled: True

# pytorch-lightning trainer params
max_epochs: 100
devices: [0]
sync_batchnorm: True
accelerator: "gpu"
strategy: "ddp"
precision: 16
log_every_n_steps: 2